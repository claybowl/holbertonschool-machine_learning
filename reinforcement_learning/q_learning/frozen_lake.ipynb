{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\clayb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.25.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\clayb\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\clayb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\clayb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gym) (1.25.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\clayb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gym) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\clayb\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gym) (0.0.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\clayb\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install gym\n",
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from gym.envs.toy_text.frozen_lake import generate_random_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v1', render_mode='ansi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "action_space_size = env.action_space.n\n",
    "state_space_size = env.observation_space.n\n",
    "\n",
    "q_table = np.zeros((state_space_size, action_space_size))\n",
    "\n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frozen_lake(desc=None, map_name=None, is_slippery=False):\n",
    "    \"\"\"\n",
    "    Load the FrozenLake environment from OpenAI's gym.\n",
    "\n",
    "    Parameters:\n",
    "    desc -- None or a list of lists containing a custom\n",
    "    description of the map to load for the environment\n",
    "    map_name -- None or a string containing the pre-made map to load\n",
    "    is_slippery -- a boolean to determine if the ice is slippery\n",
    "\n",
    "    If both desc and map_name are None, the environment will\n",
    "    load a randomly generated 8x8 map.\n",
    "\n",
    "    Returns:\n",
    "    The FrozenLake environment.\n",
    "    \"\"\"\n",
    "    if desc is None and map_name is None:\n",
    "        desc = generate_random_map(size=8)\n",
    "\n",
    "    return gym.make('FrozenLake-v1', desc=desc,\n",
    "                    map_name=map_name, is_slippery=is_slippery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'S' b'F' b'F' b'F' b'F' b'F' b'F' b'H']\n",
      " [b'H' b'F' b'F' b'F' b'F' b'H' b'F' b'F']\n",
      " [b'F' b'H' b'F' b'H' b'H' b'F' b'F' b'F']\n",
      " [b'F' b'F' b'F' b'H' b'F' b'F' b'F' b'F']\n",
      " [b'F' b'F' b'F' b'F' b'F' b'F' b'H' b'F']\n",
      " [b'F' b'F' b'F' b'F' b'F' b'F' b'F' b'F']\n",
      " [b'F' b'F' b'F' b'F' b'H' b'F' b'F' b'F']\n",
      " [b'F' b'F' b'F' b'F' b'F' b'F' b'F' b'G']]\n",
      "[(1.0, 0, 0.0, False)]\n",
      "[[b'S' b'F' b'H' b'F' b'H' b'F' b'H' b'F']\n",
      " [b'H' b'F' b'F' b'F' b'F' b'F' b'F' b'F']\n",
      " [b'F' b'F' b'F' b'F' b'F' b'F' b'F' b'F']\n",
      " [b'F' b'H' b'F' b'F' b'F' b'F' b'F' b'F']\n",
      " [b'F' b'F' b'H' b'F' b'F' b'F' b'F' b'H']\n",
      " [b'F' b'F' b'F' b'F' b'F' b'H' b'F' b'H']\n",
      " [b'F' b'F' b'H' b'F' b'H' b'F' b'H' b'F']\n",
      " [b'F' b'F' b'H' b'F' b'F' b'F' b'F' b'G']]\n",
      "[(0.3333333333333333, 0, 0.0, False), (0.3333333333333333, 0, 0.0, False), (0.3333333333333333, 8, 0.0, True)]\n",
      "[[b'S' b'F' b'F']\n",
      " [b'F' b'H' b'H']\n",
      " [b'F' b'F' b'G']]\n",
      "[[b'S' b'F' b'F' b'F']\n",
      " [b'F' b'H' b'F' b'H']\n",
      " [b'F' b'F' b'F' b'H']\n",
      " [b'H' b'F' b'F' b'G']]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "env = load_frozen_lake()\n",
    "print(env.desc)\n",
    "print(env.P[0][0])\n",
    "env = load_frozen_lake(is_slippery=True)\n",
    "print(env.desc)\n",
    "print(env.P[0][0])\n",
    "desc = [['S', 'F', 'F'], ['F', 'H', 'H'], ['F', 'F', 'G']]\n",
    "env = load_frozen_lake(desc=desc)\n",
    "print(env.desc)\n",
    "env = load_frozen_lake(map_name='4x4')\n",
    "print(env.desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_init(env):\n",
    "    \"\"\"Initialize Q-table to zeros.\"\"\"\n",
    "    return np.zeros([env.observation_space.n, env.action_space.n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 4)\n",
      "(64, 4)\n",
      "(9, 4)\n",
      "(16, 4)\n"
     ]
    }
   ],
   "source": [
    "env = load_frozen_lake()\n",
    "Q = q_init(env)\n",
    "print(Q.shape)\n",
    "env = load_frozen_lake(is_slippery=True)\n",
    "Q = q_init(env)\n",
    "print(Q.shape)\n",
    "desc = [['S', 'F', 'F'], ['F', 'H', 'H'], ['F', 'F', 'G']]\n",
    "env = load_frozen_lake(desc=desc)\n",
    "Q = q_init(env)\n",
    "print(Q.shape)\n",
    "env = load_frozen_lake(map_name='4x4')\n",
    "Q = q_init(env)\n",
    "print(Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(Q, state, epsilon):\n",
    "    \"\"\"Epsilon-greedy policy.\"\"\"\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        action = env.action_space.sample()  # Explore action space\n",
    "    else:\n",
    "        action = np.argmax(Q[state])  # Exploit learned values\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "desc = [['S', 'F', 'F'], ['F', 'H', 'H'], ['F', 'F', 'G']]\n",
    "env = load_frozen_lake(desc=desc)\n",
    "Q = q_init(env)\n",
    "Q[7] = np.array([0.5, 0.7, 1, -1])\n",
    "np.random.seed(0)\n",
    "print(epsilon_greedy(Q, 7, 0.5))\n",
    "np.random.seed(1)\n",
    "print(epsilon_greedy(Q, 7, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, Q, episodes=5000, max_steps=100,\n",
    "          alpha=0.1, gamma=0.99, epsilon=1,\n",
    "          min_epsilon=0.1, epsilon_decay=0.05):\n",
    "    \"\"\"Train agent to learn Q-values.\"\"\"\n",
    "    total_rewards = []\n",
    "    for episode in range(episodes):\n",
    "        # initialize new episode parameters\n",
    "        state = env.reset()[0]\n",
    "        done = False\n",
    "        rewards = 0\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            # exploration/exploitation trade-off\n",
    "            exploration_rate_threshold = random.uniform(0, 1)\n",
    "            if exploration_rate_threshold > epsilon:\n",
    "                action = np.argmax(Q[state,: ])\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "        new_state, reward, done, truncated, info = env.step(action)\n",
    "        # Update Q-table for Q(s,a)\n",
    "        Q[state, action] = Q[state, action] * (1 - alpha) + \\\n",
    "        alpha * (reward + gamma * np.max(Q[new_state, :]))\n",
    "\n",
    "        state = new_state\n",
    "        rewards_current_episode += reward \n",
    "\n",
    "        if done == True:\n",
    "            break\n",
    "\n",
    "        # Exploration rate decay\n",
    "        alpha = min_epsilon + \\\n",
    "    (max_steps - min_epsilon) * np.exp(-epsilon_decay*episode)\n",
    "\n",
    "        total_rewards.append(rewards)\n",
    "\n",
    "\n",
    "    return Q, total_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100. 100.]\n",
      " [100. 100.]]\n"
     ]
    }
   ],
   "source": [
    "class DummyEnv:\n",
    "    def __init__(self):\n",
    "        self.action_space = self.DummyActionSpace()\n",
    "        \n",
    "    class DummyActionSpace:\n",
    "        def sample(self):\n",
    "            return np.random.choice([0, 1])  # Assuming two actions: 0 and 1\n",
    "\n",
    "    def reset(self):\n",
    "        return 0\n",
    "\n",
    "    def step(self, action):\n",
    "        return 1, 1, False, {}\n",
    "\n",
    "\n",
    "# Main Section\n",
    "if __name__ == \"__main__\":\n",
    "    env = DummyEnv()  # Initialize the environment\n",
    "    Q = np.zeros((2, 2))  # Initialize the Q-table\n",
    "    \n",
    "    # Train the agent and get the final Q-values and total rewards\n",
    "    Q, total_rewards = train(env, Q)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(env, Q, max_steps=100):\n",
    "    \"\"\"Play agent with learned Q-values.\"\"\"\n",
    "    state = env.reset()\n",
    "    total_rewards = 0\n",
    "    for step in range(max_steps):\n",
    "        action = np.argmax(Q[state])\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        state = new_state\n",
    "        total_rewards += reward\n",
    "        if done:\n",
    "            break\n",
    "    return total_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********Q-table********\n",
      "\n",
      "[[100. 100.]\n",
      " [100. 100.]]\n"
     ]
    }
   ],
   "source": [
    "# Print updated Q-table\n",
    "print(\"\\n\\n********Q-table********\\n\")\n",
    "print(Q)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

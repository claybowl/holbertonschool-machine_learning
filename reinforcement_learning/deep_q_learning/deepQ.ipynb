{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Version Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall keras\n",
    "# !pip install keras==2.13.0  # As you specified this version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.8.0\n",
      "  Using cached tensorflow-2.8.0-cp310-cp310-win_amd64.whl (438.0 MB)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (23.5.26)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\clayb\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow==2.8.0) (3.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\clayb\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow==2.8.0) (1.1.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (16.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (4.24.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (65.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (1.15.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (2.8.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (2.8.0.dev2021122109)\n",
      "Collecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.0)\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow==2.8.0) (1.58.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n",
      "Installing collected packages: keras, tensorflow\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.1.0\n",
      "    Uninstalling Keras-2.1.0:\n",
      "      Successfully uninstalled Keras-2.1.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.13.0\n",
      "    Uninstalling tensorflow-2.13.0:\n",
      "      Successfully uninstalled tensorflow-2.13.0\n",
      "  Rolling back uninstall of tensorflow\n",
      "  Moving to c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages\\tensorflow-2.13.0.dist-info\\\n",
      "   from C:\\Users\\clayb\\anaconda3\\envs\\deep_py\\Lib\\site-packages\\~ensorflow-2.13.0.dist-info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\clayb\\\\Anaconda3\\\\envs\\\\deep_py\\\\Lib\\\\site-packages\\\\tensorflow\\\\lite\\\\experimental\\\\microfrontend\\\\python\\\\ops\\\\_audio_microfrontend_op.so'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\clayb\\appdata\\roaming\\python\\python310\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from gym) (1.24.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\clayb\\appdata\\roaming\\python\\python310\\site-packages (from gym) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\clayb\\appdata\\roaming\\python\\python310\\site-packages (from gym) (0.0.8)\n",
      "Collecting keras==2.1.0\n",
      "  Using cached Keras-2.1.0-py2.py3-none-any.whl (302 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from keras==2.1.0) (1.24.3)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\clayb\\appdata\\roaming\\python\\python310\\site-packages (from keras==2.1.0) (1.11.2)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from keras==2.1.0) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from keras==2.1.0) (6.0.1)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.8.0\n",
      "    Uninstalling keras-2.8.0:\n",
      "      Successfully uninstalled keras-2.8.0\n",
      "Successfully installed keras-2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.13.0 requires keras<2.14,>=2.13.1, but you have keras 2.1.0 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires tensorboard<2.14,>=2.13, but you have tensorboard 2.8.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-rl2 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from keras-rl2) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow->keras-rl2) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\clayb\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (22.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (4.24.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (65.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (1.58.0)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-intel==2.13.0->tensorflow->keras-rl2)\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (2.13.0)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-intel==2.13.0->tensorflow->keras-rl2)\n",
      "  Obtaining dependency information for keras<2.14,>=2.13.1 from https://files.pythonhosted.org/packages/2e/f3/19da7511b45e80216cbbd9467137b2d28919c58ba1ccb971435cb631e470/keras-2.13.1-py3-none-any.whl.metadata\n",
      "  Using cached keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow->keras-rl2) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow->keras-rl2) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2) (2.23.0)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2)\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/da/61/6e9ff8258422d287eec718872fb71e05324356722ab658c8afda25f51539/tensorboard_data_server-0.7.1-py3-none-any.whl.metadata\n",
      "  Using cached tensorboard_data_server-0.7.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow->keras-rl2) (3.2.2)\n",
      "Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Using cached tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: tensorboard-data-server, keras, google-auth-oauthlib, tensorboard\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.6.1\n",
      "    Uninstalling tensorboard-data-server-0.6.1:\n",
      "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.1.0\n",
      "    Uninstalling Keras-2.1.0:\n",
      "      Successfully uninstalled Keras-2.1.0\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.4.6\n",
      "    Uninstalling google-auth-oauthlib-0.4.6:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.6\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.8.0\n",
      "    Uninstalling tensorboard-2.8.0:\n",
      "      Successfully uninstalled tensorboard-2.8.0\n",
      "Successfully installed google-auth-oauthlib-1.0.0 keras-2.13.1 tensorboard-2.13.0 tensorboard-data-server-0.7.1\n",
      "Requirement already satisfied: h5py in c:\\users\\clayb\\appdata\\roaming\\python\\python310\\site-packages (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from h5py) (1.24.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (10.0.0)\n",
      "Requirement already satisfied: gym[atari] in c:\\users\\clayb\\appdata\\roaming\\python\\python310\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from gym[atari]) (1.24.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\clayb\\appdata\\roaming\\python\\python310\\site-packages (from gym[atari]) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\clayb\\appdata\\roaming\\python\\python310\\site-packages (from gym[atari]) (0.0.8)\n",
      "Requirement already satisfied: ale-py~=0.8.0 in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from gym[atari]) (0.8.1)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from ale-py~=0.8.0->gym[atari]) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from ale-py~=0.8.0->gym[atari]) (4.5.0)\n",
      "Requirement already satisfied: atari-py in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (0.2.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from atari-py) (1.24.3)\n",
      "Requirement already satisfied: six in c:\\users\\clayb\\anaconda3\\envs\\deep_py\\lib\\site-packages (from atari-py) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.8.0\n",
    "!pip install gym\n",
    "!pip install keras==2.1.0\n",
    "!pip install keras-rl2\n",
    "!pip install h5py\n",
    "!pip install Pillow\n",
    "!pip install gym[atari]\n",
    "!pip install atari-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\clayb\\Documents\\GitHub\\holbertonschool-machine_learning\\reinforcement_learning\\deep_q_learning\\deepQ.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/clayb/Documents/GitHub/holbertonschool-machine_learning/reinforcement_learning/deep_q_learning/deepQ.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/clayb/Documents/GitHub/holbertonschool-machine_learning/reinforcement_learning/deep_q_learning/deepQ.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgym\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/clayb/Documents/GitHub/holbertonschool-machine_learning/reinforcement_learning/deep_q_learning/deepQ.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/clayb/Documents/GitHub/holbertonschool-machine_learning/reinforcement_learning/deep_q_learning/deepQ.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# import atari\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/clayb/Documents/GitHub/holbertonschool-machine_learning/reinforcement_learning/deep_q_learning/deepQ.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mc:\\Users\\clayb\\Anaconda3\\envs\\deep_py\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clayb\\Anaconda3\\envs\\deep_py\\lib\\site-packages\\tensorflow\\python\\__init__.py:37\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\clayb\\Anaconda3\\envs\\deep_py\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:29\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mabsl\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[0;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m function_pb2\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m config_pb2\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m rewriter_config_pb2\n",
      "File \u001b[1;32mc:\\Users\\clayb\\Anaconda3\\envs\\deep_py\\lib\\site-packages\\tensorflow\\core\\framework\\function_pb2.py:16\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m attr_value_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_attr__value__pb2\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m node_def_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_node__def__pb2\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m op_def_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_op__def__pb2\n",
      "File \u001b[1;32mc:\\Users\\clayb\\Anaconda3\\envs\\deep_py\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:16\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__pb2\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m types_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_types__pb2\n",
      "File \u001b[1;32mc:\\Users\\clayb\\Anaconda3\\envs\\deep_py\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:16\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m resource_handle_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m types_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_types__pb2\n",
      "File \u001b[1;32mc:\\Users\\clayb\\Anaconda3\\envs\\deep_py\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:16\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m types_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_types__pb2\n\u001b[0;32m     20\u001b[0m DESCRIPTOR \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mFileDescriptor(\n\u001b[0;32m     21\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow/core/framework/resource_handle.proto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m   package\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m   ,\n\u001b[0;32m     27\u001b[0m   dependencies\u001b[39m=\u001b[39m[tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[39m.\u001b[39mDESCRIPTOR,tensorflow_dot_core_dot_framework_dot_types__pb2\u001b[39m.\u001b[39mDESCRIPTOR,])\n",
      "File \u001b[1;32mc:\\Users\\clayb\\Anaconda3\\envs\\deep_py\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36\u001b[0m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[0;32m     18\u001b[0m DESCRIPTOR \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mFileDescriptor(\n\u001b[0;32m     19\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow/core/framework/tensor_shape.proto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m   package\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m   serialized_pb\u001b[39m=\u001b[39m_b(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m,tensorflow/core/framework/tensor_shape.proto\u001b[39m\u001b[39m\\x12\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mtensorflow\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mz\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x10\u001b[39;00m\u001b[39mTensorShapeProto\u001b[39m\u001b[39m\\x12\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x03\u001b[39;00m\u001b[39m\\x64\u001b[39;00m\u001b[39mim\u001b[39m\u001b[39m\\x18\u001b[39;00m\u001b[39m\\x02\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\x03\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m\\x0b\u001b[39;00m\u001b[39m\\x32\u001b[39;00m\u001b[39m .tensorflow.TensorShapeProto.Dim\u001b[39m\u001b[39m\\x12\u001b[39;00m\u001b[39m\\x14\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x0c\u001b[39;00m\u001b[39munknown_rank\u001b[39m\u001b[39m\\x18\u001b[39;00m\u001b[39m\\x03\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m\\x08\u001b[39;00m\u001b[39m\\x1a\u001b[39;00m\u001b[39m!\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x03\u001b[39;00m\u001b[39m\\x44\u001b[39;00m\u001b[39mim\u001b[39m\u001b[39m\\x12\u001b[39;00m\u001b[39m\\x0c\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x04\u001b[39;00m\u001b[39msize\u001b[39m\u001b[39m\\x18\u001b[39;00m\u001b[39m\\x01\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m\\x03\u001b[39;00m\u001b[39m\\x12\u001b[39;00m\u001b[39m\\x0c\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x04\u001b[39;00m\u001b[39mname\u001b[39m\u001b[39m\\x18\u001b[39;00m\u001b[39m\\x02\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mB\u001b[39m\u001b[39m\\x87\u001b[39;00m\u001b[39m\\x01\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x18\u001b[39;00m\u001b[39morg.tensorflow.frameworkB\u001b[39m\u001b[39m\\x11\u001b[39;00m\u001b[39mTensorShapeProtosP\u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39mZSgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\u001b[39m\u001b[39m\\xf8\u001b[39;00m\u001b[39m\\x01\u001b[39;00m\u001b[39m\\x01\u001b[39;00m\u001b[39m\\x62\u001b[39;00m\u001b[39m\\x06\u001b[39;00m\u001b[39mproto3\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     29\u001b[0m _TENSORSHAPEPROTO_DIM \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mDescriptor(\n\u001b[0;32m     30\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDim\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m   full_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow.TensorShapeProto.Dim\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     32\u001b[0m   filename\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     33\u001b[0m   file\u001b[39m=\u001b[39mDESCRIPTOR,\n\u001b[0;32m     34\u001b[0m   containing_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     35\u001b[0m   fields\u001b[39m=\u001b[39m[\n\u001b[1;32m---> 36\u001b[0m     _descriptor\u001b[39m.\u001b[39;49mFieldDescriptor(\n\u001b[0;32m     37\u001b[0m       name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msize\u001b[39;49m\u001b[39m'\u001b[39;49m, full_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtensorflow.TensorShapeProto.Dim.size\u001b[39;49m\u001b[39m'\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m     38\u001b[0m       number\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, cpp_type\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, label\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     39\u001b[0m       has_default_value\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, default_value\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m     40\u001b[0m       message_type\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, enum_type\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, containing_type\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     41\u001b[0m       is_extension\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, extension_scope\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     42\u001b[0m       serialized_options\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, file\u001b[39m=\u001b[39;49mDESCRIPTOR),\n\u001b[0;32m     43\u001b[0m     _descriptor\u001b[39m.\u001b[39mFieldDescriptor(\n\u001b[0;32m     44\u001b[0m       name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m, full_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow.TensorShapeProto.Dim.name\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     45\u001b[0m       number\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m, cpp_type\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     46\u001b[0m       has_default_value\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, default_value\u001b[39m=\u001b[39m_b(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     47\u001b[0m       message_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, enum_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, containing_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m       is_extension\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, extension_scope\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     49\u001b[0m       serialized_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, file\u001b[39m=\u001b[39mDESCRIPTOR),\n\u001b[0;32m     50\u001b[0m   ],\n\u001b[0;32m     51\u001b[0m   extensions\u001b[39m=\u001b[39m[\n\u001b[0;32m     52\u001b[0m   ],\n\u001b[0;32m     53\u001b[0m   nested_types\u001b[39m=\u001b[39m[],\n\u001b[0;32m     54\u001b[0m   enum_types\u001b[39m=\u001b[39m[\n\u001b[0;32m     55\u001b[0m   ],\n\u001b[0;32m     56\u001b[0m   serialized_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     57\u001b[0m   is_extendable\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     58\u001b[0m   syntax\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mproto3\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     59\u001b[0m   extension_ranges\u001b[39m=\u001b[39m[],\n\u001b[0;32m     60\u001b[0m   oneofs\u001b[39m=\u001b[39m[\n\u001b[0;32m     61\u001b[0m   ],\n\u001b[0;32m     62\u001b[0m   serialized_start\u001b[39m=\u001b[39m\u001b[39m149\u001b[39m,\n\u001b[0;32m     63\u001b[0m   serialized_end\u001b[39m=\u001b[39m\u001b[39m182\u001b[39m,\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     66\u001b[0m _TENSORSHAPEPROTO \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mDescriptor(\n\u001b[0;32m     67\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTensorShapeProto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     68\u001b[0m   full_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow.TensorShapeProto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m   serialized_end\u001b[39m=\u001b[39m\u001b[39m182\u001b[39m,\n\u001b[0;32m    101\u001b[0m )\n\u001b[0;32m    103\u001b[0m _TENSORSHAPEPROTO_DIM\u001b[39m.\u001b[39mcontaining_type \u001b[39m=\u001b[39m _TENSORSHAPEPROTO\n",
      "File \u001b[1;32mc:\\Users\\clayb\\Anaconda3\\envs\\deep_py\\lib\\site-packages\\google\\protobuf\\descriptor.py:561\u001b[0m, in \u001b[0;36mFieldDescriptor.__new__\u001b[1;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m, name, full_name, index, number, \u001b[39mtype\u001b[39m, cpp_type, label,\n\u001b[0;32m    556\u001b[0m             default_value, message_type, enum_type, containing_type,\n\u001b[0;32m    557\u001b[0m             is_extension, extension_scope, options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    558\u001b[0m             serialized_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    559\u001b[0m             has_default_value\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, containing_oneof\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json_name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    560\u001b[0m             file\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, create_key\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m   _message\u001b[39m.\u001b[39;49mMessage\u001b[39m.\u001b[39;49m_CheckCalledFromGeneratedFile()\n\u001b[0;32m    562\u001b[0m   \u001b[39mif\u001b[39;00m is_extension:\n\u001b[0;32m    563\u001b[0m     \u001b[39mreturn\u001b[39;00m _message\u001b[39m.\u001b[39mdefault_pool\u001b[39m.\u001b[39mFindExtensionByName(full_name)\n",
      "\u001b[1;31mTypeError\u001b[0m: Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# import atari\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(693650678, 2973253328)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Gym environment\n",
    "ENV_NAME = 'Breakout-v0'\n",
    "env = gym.make(ENV_NAME)\n",
    "np.random.seed(123)\n",
    "env.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of actions\n",
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "input_shape = (84, 84)\n",
    "window_length = 4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_model = Sequential()\n",
    "train_model.add(Flatten(input_shape=(3,) + env.observation_space.shape))\n",
    "train_model.add(Dense(64, activation='relu'))\n",
    "train_model.add(Dense(32, activation='relu'))\n",
    "train_model.add(Dense(16, activation='relu'))\n",
    "train_model.add(Dense(nb_actions, activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of actions\n",
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "input_shape = (84, 84)\n",
    "window_length = 4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Permute((2, 3, 1), input_shape=(window_length,) + input_shape))\n",
    "model.add(Convolution2D(32, (8, 8), strides=(4, 4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (4, 4), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (3, 3), strides=(1, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install baselines\n",
    "from baselines.common.atari_wrappers import make_atari, wrap_deepmind\n",
    "from baselines import deepq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    env = make_atari('BreakoutNoFrameskip-v4')\n",
    "    env = wrap_deepmind(env, frame_stack=True)\n",
    "    \n",
    "    model = deepq.models.cnn_to_mlp(\n",
    "        convs=[(32, 8, 4), (64, 4, 2), (64, 3, 1)],\n",
    "        hiddens=[256],\n",
    "        dueling=True\n",
    "    )\n",
    "    \n",
    "    act = deepq.learn(\n",
    "        env,\n",
    "        q_func=model,\n",
    "        lr=0.00025,\n",
    "        max_timesteps=2000000,\n",
    "        buffer_size=10000,\n",
    "        exploration_fraction=0.1,\n",
    "        exploration_final_eps=0.01,\n",
    "        print_freq=10,\n",
    "        param_noise=True\n",
    "    )\n",
    "    \n",
    "    act.save(\"breakout_model.pkl\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Keras symbolic inputs/outputs do not implement `__len__`. You may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model. This error will also get raised if you try asserting a symbolic input/output directly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\clayb\\Documents\\GitHub\\holbertonschool-machine_learning\\reinforcement_learning\\deep_q_learning\\deepQ.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/clayb/Documents/GitHub/holbertonschool-machine_learning/reinforcement_learning/deep_q_learning/deepQ.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m memory \u001b[39m=\u001b[39m SequentialMemory(limit\u001b[39m=\u001b[39m\u001b[39m1000000\u001b[39m, window_length\u001b[39m=\u001b[39mwindow_length)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/clayb/Documents/GitHub/holbertonschool-machine_learning/reinforcement_learning/deep_q_learning/deepQ.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m policy \u001b[39m=\u001b[39m EpsGreedyQPolicy()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/clayb/Documents/GitHub/holbertonschool-machine_learning/reinforcement_learning/deep_q_learning/deepQ.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dqn \u001b[39m=\u001b[39m DQNAgent(model\u001b[39m=\u001b[39;49mmodel, nb_actions\u001b[39m=\u001b[39;49mnb_actions, memory\u001b[39m=\u001b[39;49mmemory, nb_steps_warmup\u001b[39m=\u001b[39;49m\u001b[39m50000\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/clayb/Documents/GitHub/holbertonschool-machine_learning/reinforcement_learning/deep_q_learning/deepQ.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                target_model_update\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m, policy\u001b[39m=\u001b[39;49mpolicy)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/clayb/Documents/GitHub/holbertonschool-machine_learning/reinforcement_learning/deep_q_learning/deepQ.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m dqn\u001b[39m.\u001b[39mcompile(Adam(lr\u001b[39m=\u001b[39m\u001b[39m0.00025\u001b[39m), metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\rl\\agents\\dqn.py:108\u001b[0m, in \u001b[0;36mDQNAgent.__init__\u001b[1;34m(self, model, policy, test_policy, enable_double_dqn, enable_dueling_network, dueling_type, *args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39msuper\u001b[39m(DQNAgent, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m \u001b[39m# Validate (important) input.\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model\u001b[39m.\u001b[39moutput, \u001b[39m'\u001b[39m\u001b[39m__len__\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39;49m(model\u001b[39m.\u001b[39;49moutput) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    109\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mModel \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m has more than one output. DQN expects a model that has a single output.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(model))\n\u001b[0;32m    110\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39moutput\u001b[39m.\u001b[39m_keras_shape \u001b[39m!=\u001b[39m (\u001b[39mNone\u001b[39;00m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_actions):\n",
      "File \u001b[1;32mc:\\Users\\clayb\\Anaconda3\\envs\\deep_py\\lib\\site-packages\\keras\\src\\engine\\keras_tensor.py:246\u001b[0m, in \u001b[0;36mKerasTensor.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 246\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    247\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mKeras symbolic inputs/outputs do not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mimplement `__len__`. You may be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrying to pass Keras symbolic inputs/outputs \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto a TF API that does not register dispatching, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    251\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpreventing Keras from automatically \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    252\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mconverting the API call to a lambda layer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39min the Functional Model. This error will also get raised \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    254\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mif you try asserting a symbolic input/output directly.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    255\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Keras symbolic inputs/outputs do not implement `__len__`. You may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model. This error will also get raised if you try asserting a symbolic input/output directly."
     ]
    }
   ],
   "source": [
    "# Configure and compile the agent\n",
    "memory = SequentialMemory(limit=1000000, window_length=window_length)\n",
    "policy = EpsGreedyQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=50000,\n",
    "               target_model_update=10000, policy=policy)\n",
    "dqn.compile(Adam(lr=0.00025), metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the agent\n",
    "dqn.fit(env, nb_steps=1750000, visualize=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final policy network\n",
    "dqn.save_weights('policy.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Permute((2, 3, 1), input_shape=(window_length,) + input_shape))\n",
    "model.add(Convolution2D(32, (8, 8), strides=(4, 4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (4, 4), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (3, 3), strides=(1, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and compile the agent\n",
    "memory = SequentialMemory(limit=1000000, window_length=window_length)\n",
    "policy = GreedyQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=50000,\n",
    "               target_model_update=10000, policy=policy)\n",
    "dqn.compile(Adam(lr=0.00025), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained weights\n",
    "dqn.load_weights('policy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the agent\n",
    "dqn.test(env, nb_episodes=10, visualize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

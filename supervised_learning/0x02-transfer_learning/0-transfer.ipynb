{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "**We first import the necessary libraries and define the preprocess_data function. This function takes the CIFAR-10 dataset (X, Y) and preprocesses it, including resizing the images and converting the labels to one-hot encoding.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m \u001b[39mimport\u001b[39;00m ResNet50\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m cifar10\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.layers import Lambda, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data\n",
    "- Takes the CIFAR-10 dataset (X, Y) and preprocesses it, resizes the images and converts the labels to one-hot vectors.\n",
    "- The first line of code creates a new array X_p with the same shape and content as X, but with the data type converted to float32.\n",
    "- Next, we normalize image data by dividing each pixel value by 255. This scales the pixel values to the range [0, 1].\n",
    "- Next, we resize images to 224x224 pixels (the required size for ResNet50 model). Convert back to numpy array.\n",
    "- Convert labels into one-hot vectors using keras 'to_categorical' function. In this case, each label is represented as a binary vector of length 10 (the number of classes in CIFAR-10), with a 1 at the index corresponding to the class and 0s elsewhere.\n",
    "- Finally, the function returns the preprocessed image data (X_p) and labels (Y_p) as a tuple.\n",
    "\n",
    "**In summary, the preprocess_data function converts the image data to float32, normalizes it, resizes the images, and converts the labels to one-hot encoding. These preprocessing steps are crucial for preparing the dataset for training a CNN model, such as the one used in this task.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, Y):\n",
    "    \"\"\"preprocesses the data for your model\"\"\"\n",
    "    X_p = X.astype('float32')\n",
    "    X_p /= 255\n",
    "    X_p = tf.image.resize(X_p, (224, 224)).numpy()\n",
    "\n",
    "    Y_p = to_categorical(Y, 10)\n",
    "\n",
    "    return X_p, Y_p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model\n",
    "- Creates a CNN model based on pre-trained ResNet50 architecture with custom top layers for classifying images from CIFAR-10 dataset.\n",
    "- The first line of code creates a ResNet50 model with weights pre-trained on ImageNet. The include_top argument is set to False, which means that the top layers of the model are not included. This is because we want to add our own custom top layers to the model.\n",
    "- Next, we iterate through layers of the base model and set their 'trainable' attribute to 'False' freezing layers (their weights won't be updated during training process) allowing us to leverage knowledge learned by the pre-trained model and speeds up process.\n",
    "- Add lambda layer to resize images using TensorFlow's tf.image.resize function\n",
    "- Create new top for the model by adding custom layers that will be responsible for the classification task. First, we add a GlobalAveragePooling2D layer, which computes the average value of each feature map from the base model's output. This layer reduces the spatial dimensions and flattens the feature maps.\n",
    "- Next, we add 'Dense' layer with 10 units (for number of classes in CIFAR-10 dataset) and 'softmax' activation function.\n",
    "- Create new model combining ResNet50 architecture with custom top layers.\n",
    "- Finally, compile the model using 'categorical_crossentropy' loss function, 'adam' optimizer, and 'accuracy' metric.\n",
    "\n",
    "**In summary, the create_model function creates a CNN model based on the pre-trained ResNet50 architecture with custom top layers for CIFAR-10 classification. The base model layers are frozen, and the model is compiled with the Adam optimizer, categorical crossentropy loss, and accuracy as a metric.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"creates the model for training\"\"\"\n",
    "    base_model = ResNet50(weights='imagenet', input_shape=(224,224, 3), include_top=False)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    resize_layer = Lambda(lambda image: tf.image.resize(image, (224,224)))\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    # Create new model with our custum top layers\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Script\n",
    "\n",
    "- The CIFAR-10 dataset is loaded using the Keras cifar10.load_data() function, which returns the training and testing data as tuples. The dataset is then preprocessed using the preprocess_data function.\n",
    "- The create_model function is called to create the CNN model based on the pre-trained ResNet50 architecture, with custom top layers for classifying the CIFAR-10 dataset.\n",
    "- An ImageDataGenerator is used to augment the training data by applying random transformations, such as rotation, width and height shift, and horizontal flipping. This technique helps improve the model's generalization capabilities.\n",
    "- The model is then trained for 50 epochs using the augmented training data, with a batch size of 64. The testing data is used as validation data during training.\n",
    "- The trained model is saved in the current working directory as a file named cifar10.h5.\n",
    "- The model is evaluated on the testing data using the evaluate method, and the validation accuracy is printed.\n",
    "- Finally, an assertion checks if the validation accuracy is 87% or higher, as specified in the task requirements.\n",
    "\n",
    "**In summary, this code snippet loads and preprocesses the CIFAR-10 dataset, creates a CNN model based on the pre-trained ResNet50 architecture, trains the model with data augmentation, saves the model, and evaluates its performance on the testing data. The validation accuracy must be 87% or higher to pass the assertion check.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cifar10' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m      2\u001b[0m     \u001b[39m# load and pre-process CIFAR-10 dataset\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     (X_train, Y_train), (X_test, Y_test) \u001b[39m=\u001b[39m cifar10\u001b[39m.\u001b[39mload_data()\n\u001b[1;32m      4\u001b[0m     X_train, Y_train \u001b[39m=\u001b[39m preprocess_data(X_train, Y_train)\n\u001b[1;32m      5\u001b[0m     X_test, Y_test \u001b[39m=\u001b[39m preprocess_data(X_test, Y_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cifar10' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # load and pre-process CIFAR-10 dataset\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "    X_train, Y_train = preprocess_data(X_train, Y_train)\n",
    "    X_test, Y_test = preprocess_data(X_test, Y_test)\n",
    "\n",
    "    # create model\n",
    "    model = create_model()\n",
    "\n",
    "    # train model\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "    datagen.fit(X_train)\n",
    "    history = model.fit(datagen.flow(X_train, Y_train, batch_size=64),\n",
    "                        epochs=50, validation_data=(X_test, Y_test))\n",
    "\n",
    "    # save model\n",
    "    model.save('cifar10.h5')\n",
    "\n",
    "    # evaluate model\n",
    "    _, val_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Validation accuracy: {:.2f}%\".format(val_acc * 100))\n",
    "\n",
    "    # Check if the validation accuracy is 87% or higher\n",
    "    assert val_acc >= 0.87, \"The validation accuracy should be 87% or higher.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

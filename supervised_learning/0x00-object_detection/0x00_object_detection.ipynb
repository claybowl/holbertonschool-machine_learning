{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edFOugGx6KgM",
        "outputId": "b1b097c8-8d4b-49ed-9bcb-dfa284a820df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-23 19:56:05.338719: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-23 19:56:05.456199: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dojon/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-04-23 19:56:05.456216: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-04-23 19:56:06.048911: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dojon/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-04-23 19:56:06.049015: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dojon/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-04-23 19:56:06.049023: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.models import load_model\n",
        "import sys\n",
        "import h5py as h5\n",
        "import time\n",
        "import os\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SFinwYx39qXl"
      },
      "outputs": [],
      "source": [
        "class Yolo:\n",
        "    \"\"\"Uses the Yolo v3 algorithm to perform object detection\"\"\"\n",
        "\n",
        "    def __init__(self, model_path, classes_path, class_t, nms_t, anchors):\n",
        "        \"\"\"Class constructor\"\"\"\n",
        "        self.model = load_model(model_path)\n",
        "        self.class_names = self._load_classes(classes_path)\n",
        "        self.class_t = class_t\n",
        "        self.nms_t = nms_t\n",
        "        self.anchors = anchors\n",
        "\n",
        "    def _load_classes(self, classes_path):\n",
        "        \"\"\"Loads the classes from a file\"\"\"\n",
        "        with open(classes_path, 'r') as f:\n",
        "            class_names = f.readlines()\n",
        "        class_names = [c.strip() for c in class_names]\n",
        "        return class_names\n",
        "\n",
        "    @staticmethod\n",
        "    def load_images(folder_path):\n",
        "        \"\"\"Loads images from a folder\"\"\"\n",
        "        image_paths = [os.path.join(folder_path, img) for img in os.listdir(\n",
        "            folder_path) if img.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        images = [cv2.imread(image_path) for image_path in image_paths]\n",
        "        return images, image_paths\n",
        "\n",
        "    def process_outputs(self, outputs, image_size):\n",
        "        boxes = []\n",
        "        box_confidences = []\n",
        "        box_class_probs = []\n",
        "        for i in range(len(outputs)):\n",
        "            boxes.append(outputs[i][..., :4])\n",
        "            box_confidences.append(1 / (1 + np.exp(-outputs[i][..., 4:5])))\n",
        "            box_class_probs.append(1 / (1 + np.exp(-outputs[i][..., 5:])))\n",
        "        image_height, image_width = image_size\n",
        "        for i in range(len(boxes)):\n",
        "            grid_width = outputs[i].shape[1]\n",
        "            grid_height = outputs[i].shape[0]\n",
        "            anchor_boxes = outputs[i].shape[2]\n",
        "            for cy in range(grid_height):\n",
        "                for cx in range(grid_width):\n",
        "                    for b in range(anchor_boxes):\n",
        "                        tx, ty, tw, th = boxes[i][cy, cx, b]\n",
        "                        pw, ph = self.anchors[i][b]\n",
        "                        bx = (1 / (1 + np.exp(-tx))) + cx\n",
        "                        by = (1 / (1 + np.exp(-ty))) + cy\n",
        "                        bw = pw * np.exp(tw)\n",
        "                        bh = ph * np.exp(th)\n",
        "                        bx /= grid_width\n",
        "                        by /= grid_height\n",
        "                        bw /= self.model.input.shape[1]\n",
        "                        bh /= self.model.input.shape[2]\n",
        "                        x1 = (bx - (bw / 2)) * image_width\n",
        "                        y1 = (by - (bh / 2)) * image_height\n",
        "                        x2 = (bx + (bw / 2)) * image_width\n",
        "                        y2 = (by + (bh / 2)) * image_height\n",
        "                        boxes[i][cy, cx, b] = [x1, y1, x2, y2]\n",
        "        return (boxes, box_confidences, box_class_probs)\n",
        "\n",
        "    def filter_boxes(self, boxes, box_confidences, box_class_probs):\n",
        "        filtered_boxes, box_classes_list, box_scores_list = None, [], []\n",
        "        for i in range(len(boxes)):\n",
        "            new_box_score = box_confidences[i] * box_class_probs[i]\n",
        "            new_box_class = np.argmax(new_box_score, axis=-1)\n",
        "            new_box_score = np.max(new_box_score, axis=-1)\n",
        "\n",
        "            box_classes_list.append(new_box_class.reshape(-1))\n",
        "            box_scores_list.append(new_box_score.reshape(-1))\n",
        "\n",
        "        box_scores_all = np.concatenate(box_scores_list)\n",
        "        box_classes_all = np.concatenate(box_classes_list)\n",
        "        box_mask = box_scores_all >= self.class_t\n",
        "\n",
        "        filtered_boxes = np.concatenate(\n",
        "            [box.reshape(-1, 4) for box in boxes], axis=0)\n",
        "        filtered_boxes = filtered_boxes[box_mask]\n",
        "\n",
        "        box_classes = box_classes_all[box_mask]\n",
        "        box_scores = box_scores_all[box_mask]\n",
        "\n",
        "        return filtered_boxes, box_classes, box_scores\n",
        "\n",
        "    def intersection_over_union(self, box1, boxes):\n",
        "            \"\"\"Calculate the Intersection over Union (IoU) for a given box and multiple other boxes.\"\"\"\n",
        "            x1 = np.maximum(box1[0], boxes[0])\n",
        "            y1 = np.maximum(box1[1], boxes[1])\n",
        "            x2 = np.minimum(box1[2], boxes[2])\n",
        "            y2 = np.minimum(box1[3], boxes[3])\n",
        "\n",
        "            intersection_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "            box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "            boxes_area = (boxes[2] - boxes[0]) * (boxes[3] - boxes[1])\n",
        "\n",
        "            union_area = box1_area + boxes_area - intersection_area\n",
        "\n",
        "            return intersection_area / union_area\n",
        "\n",
        "    def non_max_suppression(self, filtered_boxes, box_classes, box_scores):\n",
        "        \"\"\"\n",
        "        Applies non-maximum suppression to the filtered boxes.\n",
        "\n",
        "        If use_tf is True, it uses TensorFlow's non_max_suppression implementation.\n",
        "        Otherwise, it uses the provided custom implementation.\n",
        "        \"\"\"\n",
        "        unique_classes = np.unique(box_classes)\n",
        "        box_predictions = []\n",
        "        predicted_box_classes = []\n",
        "        predicted_box_scores = []\n",
        "\n",
        "        for cls in unique_classes:\n",
        "            idxs = np.where(box_classes == cls)\n",
        "            cls_boxes = filtered_boxes[idxs]\n",
        "            cls_box_scores = box_scores[idxs]\n",
        "\n",
        "            while len(cls_boxes) > 0:\n",
        "                max_score_idx = np.argmax(cls_box_scores)\n",
        "                box_predictions.append(cls_boxes[max_score_idx])\n",
        "                predicted_box_classes.append(cls)\n",
        "                predicted_box_scores.append(cls_box_scores[max_score_idx])\n",
        "\n",
        "                iou_scores = [self.intersection_over_union(cls_boxes[max_score_idx],\n",
        "                                        box) for box in cls_boxes]\n",
        "                to_remove = np.where(np.array(iou_scores) > self.nms_t)\n",
        "                cls_boxes = np.delete(cls_boxes, to_remove, axis=0)\n",
        "                cls_box_scores = np.delete(cls_box_scores, to_remove, axis=0)\n",
        "\n",
        "        return np.array(box_predictions), np.array(predicted_box_classes), np.array(predicted_box_scores)\n",
        "\n",
        "    def preprocess_images(self, images):\n",
        "        \"\"\"Preprocess images for the YOLO model\"\"\"\n",
        "        input_h = self.model.input_shape[1]\n",
        "        input_w = self.model.input_shape[2]\n",
        "        ni = len(images)\n",
        "        pimages = np.empty((ni, input_h, input_w, 3))\n",
        "        image_shapes = np.empty((ni, 2))\n",
        "\n",
        "        for i, img in enumerate(images):\n",
        "            image_shapes[i] = img.shape[:2]\n",
        "            resized_img = cv2.resize(img, (input_w, input_h), interpolation=cv2.INTER_CUBIC)\n",
        "            pimages[i] = resized_img / 255\n",
        "\n",
        "        return pimages, image_shapes\n",
        "\n",
        "    def show_boxes(self, image, boxes, box_classes, box_scores, file_name):\n",
        "        \"\"\"Displays the image with all boundary boxes, class names, and box scores\"\"\"\n",
        "        for i, box in enumerate(boxes):\n",
        "\n",
        "            # unpack box coordinates\n",
        "            x1, y1, x2, y2 = box.astype(int)\n",
        "\n",
        "            # create rectangle\n",
        "            cv2.rectangle(img=image,\n",
        "                          pt1=(x1, y1),\n",
        "                          pt2=(x2, y2),\n",
        "                          color=(255, 0, 0),\n",
        "                          thickness=2)\n",
        "\n",
        "            # add label\n",
        "            cv2.putText(img=image,\n",
        "                        text='{} {:.2f}'.format(\n",
        "                            self.class_names[box_classes[i]], box_scores[i]),\n",
        "                        org=(x1, y1 - 5),\n",
        "                        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        fontScale=0.5,\n",
        "                        color=(0, 0, 255),\n",
        "                        thickness=1,\n",
        "                        lineType=cv2.LINE_AA)\n",
        "\n",
        "        # show image\n",
        "        cv2.imshow(file_name, image)\n",
        "\n",
        "        # wait for key press\n",
        "        key = cv2.waitKey(0)\n",
        "\n",
        "        # if 's' key is pressed, add image to 'detections' directory\n",
        "        if key == ord('s'):\n",
        "            if not os.path.exists('detections'):\n",
        "                os.makedirs('detections')\n",
        "            cv2.imwrite(os.path.join('detections', file_name), image)\n",
        "\n",
        "        # close image\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "def process_images(self, folder_path):\n",
        "    \"\"\"Process all images located in folder_path\"\"\"\n",
        "    images, image_paths = self.load_images(folder_path)\n",
        "    pimages, image_shapes = self.preprocess_images(images)\n",
        "    outputs = self.model.predict(pimages)\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    for i, image in enumerate(images):\n",
        "        image_outputs = [output[i] for output in outputs]\n",
        "        boxes, box_confidences, box_class_probs = self.process_outputs(\n",
        "            image_outputs, image_shapes[i])\n",
        "        filtered_boxes, box_classes, box_scores = self.filter_boxes(\n",
        "            boxes, box_confidences, box_class_probs)\n",
        "        box_predictions, predicted_box_classes, predicted_box_scores = self.non_max_suppression(\n",
        "            filtered_boxes, box_classes, box_scores)\n",
        "\n",
        "        predictions.append(\n",
        "            (box_predictions, predicted_box_classes, predicted_box_scores))\n",
        "\n",
        "    for i, prediction in enumerate(predictions):\n",
        "        self.show_boxes(images[i], *prediction, image_paths[i].split('/')[-1])\n",
        "\n",
        "    return predictions, image_paths\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV0M2HxG_dDv"
      },
      "source": [
        "# Task 0 Main File:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xo_-mHGW_jD0"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    import numpy as np\n",
        "\n",
        "    np.random.seed(0)\n",
        "    anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
        "                        [[30, 61], [62, 45], [59, 119]],\n",
        "                        [[10, 13], [16, 30], [33, 23]]])\n",
        "    yolo = Yolo('data/yolo.h5', 'data/coco_classes.txt', 0.6, 0.5, anchors)\n",
        "    yolo.model.summary()\n",
        "    print('Class names:', yolo.class_names)\n",
        "    print('Class threshold:', yolo.class_t)\n",
        "    print('NMS threshold:', yolo.nms_t)\n",
        "    print('Anchor boxes:', yolo.anchors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUw-K9JSdEBq"
      },
      "source": [
        "# Task 1 Main File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0F-Jj77by-E"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    np.random.seed(0)\n",
        "    anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
        "                        [[30, 61], [62, 45], [59, 119]],\n",
        "                        [[10, 13], [16, 30], [33, 23]]])\n",
        "    yolo = Yolo('data/yolo.h5', 'data/coco_classes.txt', 0.6, 0.5, anchors)\n",
        "    output1 = np.random.randn(13, 13, 3, 85)\n",
        "    output2 = np.random.randn(26, 26, 3, 85)\n",
        "    output3 = np.random.randn(52, 52, 3, 85)\n",
        "    boxes, box_confidences, box_class_probs = yolo.process_outputs([output1, output2, output3], np.array([500, 700]))\n",
        "    print('Boxes:', boxes)\n",
        "    print('Box confidences:', box_confidences)\n",
        "    print('Box class probabilities:', box_class_probs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GxeN7wEw6fo"
      },
      "source": [
        "# Task 2 Main File:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ir4g6bpw9hI"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    np.random.seed(0)\n",
        "    anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
        "                        [[30, 61], [62, 45], [59, 119]],\n",
        "                        [[10, 13], [16, 30], [33, 23]]])\n",
        "    yolo = Yolo('data/yolo.h5', 'data/coco_classes.txt', 0.6, 0.5, anchors)\n",
        "    output1 = np.random.randn(13, 13, 3, 85)\n",
        "    output2 = np.random.randn(26, 26, 3, 85)\n",
        "    output3 = np.random.randn(52, 52, 3, 85)\n",
        "    boxes, box_confidences, box_class_probs = yolo.process_outputs([output1, output2, output3], np.array([500, 700]))\n",
        "    boxes, box_classes, box_scores = yolo.filter_boxes(boxes, box_confidences, box_class_probs)\n",
        "    print('Boxes:', boxes)\n",
        "    print('Box classes:', box_classes)\n",
        "    print('Box scores:', box_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP_8rto4SFEI"
      },
      "source": [
        "# Task 3 Main File:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CmrggIxSI8T",
        "outputId": "65befe09-9bfe-4a6e-b07a-d593b28aee08"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Boxes: [[483.49145347 128.010205   552.78146847 147.87465464]\n",
            " [-38.91328475 332.66704009 102.94594841 363.78584864]\n",
            " [ 64.10861893 329.13266621 111.87941603 358.37523958]\n",
            " ...\n",
            " [130.0729606  467.20024928 172.42160784 515.90336094]\n",
            " [578.82381106  76.25699693 679.22893305 104.63320075]\n",
            " [169.12132771 304.32765204 251.1457077  342.16397829]]\n",
            "Box classes: [ 0  0  0 ... 79 79 79]\n",
            "Box scores: [0.80673525 0.80405611 0.78972362 ... 0.61758194 0.61455015 0.6001824 ]\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    np.random.seed(0)\n",
        "    anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
        "                        [[30, 61], [62, 45], [59, 119]],\n",
        "                        [[10, 13], [16, 30], [33, 23]]])\n",
        "    yolo = Yolo('data/yolo.h5', 'data/coco_classes.txt', 0.6, 0.5, anchors)\n",
        "    output1 = np.random.randn(13, 13, 3, 85)\n",
        "    output2 = np.random.randn(26, 26, 3, 85)\n",
        "    output3 = np.random.randn(52, 52, 3, 85)\n",
        "    boxes, box_confidences, box_class_probs = yolo.process_outputs([output1, output2, output3], np.array([500, 700]))\n",
        "    boxes, box_classes, box_scores = yolo.filter_boxes(boxes, box_confidences, box_class_probs)\n",
        "    boxes, box_classes, box_scores = yolo.non_max_suppression(boxes, box_classes, box_scores)\n",
        "    print('Boxes:', boxes)\n",
        "    print('Box classes:', box_classes)\n",
        "    print('Box scores:', box_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA97JoeiwXtT"
      },
      "source": [
        "# Task 4 Main file:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmoS3nA6wfVB"
      },
      "source": [
        "# Task 5 Main file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "1XZ_-9mwwi8l",
        "outputId": "69162030-4dc8-4cf8-ff79-2b7a5656aea1"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'load_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m anchors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[[\u001b[39m116\u001b[39m, \u001b[39m90\u001b[39m], [\u001b[39m156\u001b[39m, \u001b[39m198\u001b[39m], [\u001b[39m373\u001b[39m, \u001b[39m326\u001b[39m]],\n\u001b[1;32m      7\u001b[0m                     [[\u001b[39m30\u001b[39m, \u001b[39m61\u001b[39m], [\u001b[39m62\u001b[39m, \u001b[39m45\u001b[39m], [\u001b[39m59\u001b[39m, \u001b[39m119\u001b[39m]],\n\u001b[1;32m      8\u001b[0m                     [[\u001b[39m10\u001b[39m, \u001b[39m13\u001b[39m], [\u001b[39m16\u001b[39m, \u001b[39m30\u001b[39m], [\u001b[39m33\u001b[39m, \u001b[39m23\u001b[39m]]])\n\u001b[0;32m----> 9\u001b[0m yolo \u001b[39m=\u001b[39m Yolo(\u001b[39m'\u001b[39;49m\u001b[39m../data/yolo.h5\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m../data/coco_classes.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m0.6\u001b[39;49m, \u001b[39m0.5\u001b[39;49m, anchors)\n\u001b[1;32m     10\u001b[0m images, image_paths \u001b[39m=\u001b[39m yolo\u001b[39m.\u001b[39mload_images(\u001b[39m'\u001b[39m\u001b[39m../data/yolo\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m pimages, image_shapes \u001b[39m=\u001b[39m yolo\u001b[39m.\u001b[39mpreprocess_images(images)\n",
            "Cell \u001b[0;32mIn[3], line 6\u001b[0m, in \u001b[0;36mYolo.__init__\u001b[0;34m(self, model_path, classes_path, class_t, nms_t, anchors)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, model_path, classes_path, class_t, nms_t, anchors):\n\u001b[1;32m      5\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Class constructor\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m load_model(model_path)\n\u001b[1;32m      7\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_classes(classes_path)\n\u001b[1;32m      8\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_t \u001b[39m=\u001b[39m class_t\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "\n",
        "    np.random.seed(0)\n",
        "    anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
        "                        [[30, 61], [62, 45], [59, 119]],\n",
        "                        [[10, 13], [16, 30], [33, 23]]])\n",
        "    yolo = Yolo('../data/yolo.h5', '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
        "    images, image_paths = yolo.load_images('../data/yolo')\n",
        "    pimages, image_shapes = yolo.preprocess_images(images)\n",
        "    print(type(pimages), pimages.shape)\n",
        "    print(type(image_shapes), image_shapes.shape)\n",
        "    i = np.random.randint(0, len(images))\n",
        "    print(images[i].shape, ':', image_shapes[i])\n",
        "    cv2.imshow(image_paths[i], pimages[i])\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 6 Main file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-23 20:08:24.273192: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-23 20:08:24.383035: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dojon/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-04-23 20:08:24.383052: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-04-23 20:08:24.900616: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dojon/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-04-23 20:08:24.900731: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dojon/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-04-23 20:08:24.900740: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-04-23 20:08:26.148763: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-04-23 20:08:26.148875: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dojon/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-04-23 20:08:26.148931: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dojon/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-04-23 20:08:26.148980: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dojon/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-04-23 20:08:26.149029: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dojon/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-04-23 20:08:26.149077: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dojon/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-04-23 20:08:26.149124: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dojon/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-04-23 20:08:26.149221: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dojon/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-04-23 20:08:26.149270: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dojon/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2023-04-23 20:08:26.149280: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2023-04-23 20:08:26.149500: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    import numpy as np\n",
        "    Yolo = __import__('6-yolo').Yolo\n",
        "\n",
        "    np.random.seed(0)\n",
        "    anchors = np.array([[[116, 90], [156, 198], [373, 326]],\n",
        "                        [[30, 61], [62, 45], [59, 119]],\n",
        "                        [[10, 13], [16, 30], [33, 23]]])\n",
        "    yolo = Yolo('../data/yolo.h5',\n",
        "                '../data/coco_classes.txt', 0.6, 0.5, anchors)\n",
        "    images, image_paths = yolo.load_images('../data/yolo')\n",
        "    boxes = np.array([[119.22100287, 118.62197718, 567.75985556, 440.44121152],\n",
        "                      [468.53530752, 84.48338278, 696.04923556, 167.98947829],\n",
        "                      [124.2043716, 220.43365057, 319.4254314, 542.13706101]])\n",
        "    box_scores = np.array([0.99537075, 0.91536146, 0.9988506])\n",
        "    box_classes = np.array([1, 7, 16])\n",
        "    ind = 0\n",
        "    for i, name in enumerate(image_paths):\n",
        "        if \"dog.jpg\" in name:\n",
        "            ind = i\n",
        "            break\n",
        "    yolo.show_boxes(images[i], boxes, box_classes, box_scores, \"dog.jpg\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
